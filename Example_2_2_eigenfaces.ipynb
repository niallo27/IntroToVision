{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Example_2_2_eigenfaces.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPJ3N0WOa3L8w7oICkk/+Ig",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tonyscan6003/IntroToVision/blob/main/Example_2_2_eigenfaces.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHx0vv49uZRo"
      },
      "source": [
        "# Simple Facial Recognition with Eigenfaces\n",
        "\n",
        "![Eigenfaces](https://github.com/tonyscan6003/CE6003/blob/master/images/eigenfaces.jpg?raw=true)\n",
        "\n",
        "In this example we will obtain eigenfaces from a small dataset of faces.\n",
        "We will demonstrate reconstraction of faces with the eigenfaces.\n",
        "We will train a Support Vector Machine Classifier and demonstrate facial recognition. (Note that it is appropriate to use an SVM in this case as the dataset used [\"Olivetti Faces\"](https://scikit-learn.org/stable/datasets/index.html#real-world-datasets)  contains 40 people with 10 examples for each face. )\n",
        "\n",
        "This example is based on the [scikit Learn tutorial](https://scipy-lectures.org/packages/scikit-learn/auto_examples/plot_eigenfaces.html) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdx6qJvo0lR2"
      },
      "source": [
        "**HouseKeeping**: Import Packages, import sklearn dataset, divide in test and train splits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQpwnCgruYYz"
      },
      "source": [
        "from sklearn import datasets\n",
        "from skimage import feature\n",
        "from skimage import exposure\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn import decomposition\n",
        "import numpy as np\n",
        "import urllib\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Tcotie7wxo6"
      },
      "source": [
        "Load & display the Olivetti Faces - This consists of 400 faces of size 64 x 64 = 4096 pixels. (This is a sklearn built in dataset and is very simple to load) As the number of pixels is very large we need to use eignfaces to produce a representation in a more compact form, that we can use for matching/classification. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tk86U5pTv8AY"
      },
      "source": [
        "\n",
        "faces = datasets.fetch_olivetti_faces()\n",
        "faces.data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9H1HIPduwI7G"
      },
      "source": [
        "fig = plt.figure(figsize=(8, 6))\n",
        "# plot several images\n",
        "for i in range(15):\n",
        "    ax = fig.add_subplot(3, 5, i + 1, xticks=[], yticks=[])\n",
        "    ax.imshow(faces.images[i], cmap=plt.cm.bone)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MokyZd2SxoZQ"
      },
      "source": [
        "We will divide the the dataset in train and test splits. (Note that the labels are also supplied in the sklearn dataset that we loaded.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLLrl0evzK3a"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(faces.data,\n",
        "        faces.target, random_state=0)\n",
        "\n",
        "print(X_train.shape, X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rtfv9TXJzO6E"
      },
      "source": [
        "## Creating the Eigenfaces\n",
        "As we saw in the Video lesson on Eigenfaces we use Principle Component Analysis to obtain eigenvectors. The sklearn python package has a built in PCA function to enable us to quickly determine the eigenfaces from the databased of faces. We can set the parameter `n_eigenfaces` which sets the number of pca components to use as Eigenfaces, using fewer eigenfaces will give a more compact representation of the faces. However as we will see in the next section this representation is lossy and faces cannot be completely reconstructed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nu2RJtFU3HXN"
      },
      "source": [
        "n_eigenfaces = 5  # Number of eigenfaces to return (max 299)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtpbHwBU1KCt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d129f3cb-d820-42f1-a113-e38357263b07"
      },
      "source": [
        "\n",
        "pca = decomposition.PCA(n_components=n_eigenfaces, whiten=True)\n",
        "pca.fit(X_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PCA(copy=True, iterated_power='auto', n_components=100, random_state=None,\n",
              "    svd_solver='auto', tol=0.0, whiten=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCxUdsux2nuX"
      },
      "source": [
        "We wil display the 1st 30 eigenfaces obtained from the PCA. The ith eigenvector is accessed by pca.components_[i] "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KDpAIKv12md"
      },
      "source": [
        "fig = plt.figure(figsize=(16, 6))\n",
        "for i in range(min(30,n_eigenfaces)):\n",
        "    ax = fig.add_subplot(3, 10, i + 1, xticks=[], yticks=[])\n",
        "    ax.imshow(pca.components_[i].reshape(faces.images[0].shape),\n",
        "              cmap=plt.cm.bone)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vj7la9KV3Or8"
      },
      "source": [
        "## Transforming the Database & Reconstructing faces\n",
        "In this step we will transform the database of faces into it's eigenface representation. This will give use a vector for each face equal to the number of eigenfaces we choose to retain (max number of Eigenfaces = Number of faces in database -1)\n",
        "\n",
        " In the previous step we could set the parameter n_eigenfaces which controls how many eigenfaces to retain. We will investigate the quality of the face reconstruction by varying this number from a low value 5 to the max value 299, trying some values inbetween. The idea of doing this is to see what is a good minimum number of Eigenfaces we need to properly represent the faces. (Make sure you are using enough Eigenfaces before moving onto the Recognition step below.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1SwcROk6CXj"
      },
      "source": [
        "# Apply the transformation to the training and test sets.\n",
        "X_train_pca = pca.transform(X_train)\n",
        "X_test_pca = pca.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Rv4i6Mf7gr9"
      },
      "source": [
        "We then will apply the inverse PCA transform. Which will give us back the reconstructed faces. (Take a look at the stackover flow post https://stackoverflow.com/questions/55533116/pca-inverse-transform-in-sklearn which explains these 2 steps for 2D data.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLhk3Ne46LZJ"
      },
      "source": [
        "# Apply the inverse transform to training set\n",
        "X_train_recon = pca.inverse_transform(X_train_pca)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9t6ED59j8szx"
      },
      "source": [
        "We will then plot some pairs of original faces from the dataset and the reconstructed faces from the representation in our database using Eigenfaces. Change the number of eigenfaces (n_eigenfaces) above and run all the code cells from Creating the Eigenfaces to the cell below to see the quality of the reconstructed faces."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7n4V12fz8sJ0"
      },
      "source": [
        "fig = plt.figure(figsize=(2, 20))\n",
        "# plot several images\n",
        "for i in range(16):\n",
        "    ax = fig.add_subplot(14, 2, i + 1, xticks=[], yticks=[])   \n",
        "    if i % 2  ==0:\n",
        "       # plot oringial face\n",
        "       ax.imshow(X_train[i].reshape(64,64), cmap=plt.cm.bone)\n",
        "    else:\n",
        "       #plot reconstructed face \n",
        "       ax.imshow(X_train_recon[i-1].reshape(64,64), cmap=plt.cm.bone)\n",
        "fig.suptitle('Pairs of Original Database face & Reconstucted Faces from Databse with Eigenface representation = '+str(n_eigenfaces)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E30MdqixDwnS"
      },
      "source": [
        "## Recognition\n",
        "Now that we have selected the appropriate value of number eigenfaces to represent our database, we can now perform recognition between the test set and training set. The test set has alreay been converted to it's Eigenface representation. In the code cell below we will train a support vector machine classifier to perform recognition. We will use a support vector machine as we have 10 images for each person in this dataset. (In a case where we just have one image per person we would use k nearest neighbors, we could use KNN in this case also)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "se2-zdVnGPnu"
      },
      "source": [
        "Initialise & Train the support Vector machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueabOsuBFJIC"
      },
      "source": [
        "clf = svm.SVC(C=5., gamma=0.001)\n",
        "clf.fit(X_train_pca, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcWCpoUmGVXt"
      },
      "source": [
        "Apply the test set to the classifier and get a classification report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9L7oEXJFUU9"
      },
      "source": [
        "y_pred = clf.predict(X_test_pca)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Pe4Eayftg5D"
      },
      "source": [
        "Plot some examples of the Test Set (Any errors in subject labelling will be highlighted in red font)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvoAD83DFNnD"
      },
      "source": [
        "\n",
        "fig = plt.figure(figsize=(20, 15))\n",
        "for i in range(100):\n",
        "    ax = fig.add_subplot(10, 20, i + 1, xticks=[], yticks=[])\n",
        "    ax.imshow(X_test[i].reshape(faces.images[0].shape),\n",
        "              cmap=plt.cm.bone)\n",
        "    y_pred = clf.predict(X_test_pca[i, np.newaxis])[0]\n",
        "    color = ('black' if y_pred == y_test[i] else 'red')\n",
        "    ax.set_title(y_test[i],\n",
        "                 fontsize='small', color=color)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}